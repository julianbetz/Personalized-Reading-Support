<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>yokome.models.language_model &#8212; Yokome 1.0 documentation</title>
    <link rel="stylesheet" href="../../../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="yokome.models.train" href="train.html" />
    <link rel="prev" title="yokome.models.hyperoptimization" href="hyperoptimization.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../../../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../../../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../../../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../../../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../index.html">
          Yokome</a>
        <span class="navbar-text navbar-version pull-left"><b>1.0</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../../../py-modindex.html">Python Modules</a></li>
                <li><a href="../../../webextension.html">WebExtension</a></li>
                <li><a href="../../../genindex.html">Index</a></li>
                <li><a href="../../../future_work.html">Future Work</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../yokome.html"><code class="docutils literal notranslate"><span class="pre">yokome</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../webextension.html">Yokome Firefox WebExtension (JavaScript)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../future_work.html">Where to go from here</a></li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="hyperoptimization.html" title="Previous Chapter: yokome.models.hyperoptimization"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; yokome.models...</span>
    </a>
  </li>
  <li>
    <a href="train.html" title="Next Chapter: yokome.models.train"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">yokome.models.train &raquo;</span>
    </a>
  </li>
              
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="col-md-3">
        <div id="sidebar" class="bs-sidenav" role="complementary"><ul>
<li><a class="reference internal" href="#"><code class="docutils literal notranslate"><span class="pre">yokome.models.language_model</span></code></a></li>
</ul>

        </div>
      </div>
    <div class="body col-md-9 content" role="main">
      
  <div class="section" id="module-yokome.models.language_model">
<span id="yokome-models-language-model"></span><h1><code class="docutils literal notranslate"><span class="pre">yokome.models.language_model</span></code><a class="headerlink" href="#module-yokome.models.language_model" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="yokome.models.language_model.LanguageModel">
<em class="property">class </em><code class="sig-prename descclassname">yokome.models.language_model.</code><code class="sig-name descname">LanguageModel</code><span class="sig-paren">(</span><em class="sig-param">model_dir=None</em>, <em class="sig-param">params=None</em>, <em class="sig-param">seed=None</em>, <em class="sig-param">warm_start_from=None</em>, <em class="sig-param">production_mode=False</em>, <em class="sig-param">*</em>, <em class="sig-param">save_summary_steps=100</em>, <em class="sig-param">keep_checkpoint_max=5</em>, <em class="sig-param">language=None</em>, <em class="sig-param">vocabulary=None</em><span class="sig-paren">)</span><a class="headerlink" href="#yokome.models.language_model.LanguageModel" title="Permalink to this definition">¶</a></dt>
<dd><p>A neural language model that estimates the probability of a sentence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_dir</strong> (<em>str</em>) – Where to store all relevant model data.  If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, a generic location based on the current date and time will
be used.</p></li>
<li><p><strong>params</strong> (<em>dict</em>) – The model parameters.</p></li>
<li><p><strong>seed</strong> (<em>int</em>) – The seed to use for the underlying Tensorflow graph.</p></li>
<li><p><strong>warm_start_from</strong> (<em>str</em>) – A directory containing model parameter
values for initialization.</p></li>
<li><p><strong>production_mode</strong> (<em>bool</em>) – Whether to use the production or the
training model.</p></li>
<li><p><strong>save_summary_steps</strong> (<em>int</em>) – The periodicity at which to save
summaries.</p></li>
<li><p><strong>keep_checkpoint_max</strong> (<em>int</em>) – The maximum number of recent checkpoint
files to keep.</p></li>
<li><p><strong>language</strong> (<em>yokome.language.Language</em>) – The language of the language model.</p></li>
<li><p><strong>vocabulary</strong> – A mapping from input units to integer values, or a
sequence of input units.  This is used to encode the incoming data
numerically.  If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a pickled mapping is expected to be found
in the model directory, named <code class="docutils literal notranslate"><span class="pre">encoder.pickle</span></code>.  Every input unit
that is not found in this vocabulary is considered to be an
out-of-vocabulary unit.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="yokome.models.language_model.LanguageModel.estimate_probability">
<code class="sig-name descname">estimate_probability</code><span class="sig-paren">(</span><em class="sig-param">sentences</em>, <em class="sig-param">batch_size</em>, <em class="sig-param">sample_size=0</em><span class="sig-paren">)</span><a class="headerlink" href="#yokome.models.language_model.LanguageModel.estimate_probability" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimate the probability of the specified sentences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sentences</strong> – A sequence of sentences.  Each sentence will be
tokenized using the language object provided at language model
creation.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – The number of sentences to estimate the
probability for in parallel.</p></li>
<li><p><strong>sample_size</strong> (<em>int</em>) – The number of sentence alternatives to sample.
If this is greater than zero, for every list of token candidates
after tokenization, one token candidate is chosen for each sample.
If it is <code class="docutils literal notranslate"><span class="pre">0</span></code>, all sentence alternatives (i.e. all combinations of
token candidates) are enumerated and used for probability
estimation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>An iterable over one dictionary per sentence, each of the form</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s1">&#39;log2_word_probs&#39;</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">word</span> <span class="n">log</span><span class="o">-</span><span class="n">probabilities</span> <span class="n">per</span> <span class="n">alternative</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="s1">&#39;log2_sentence_probs&#39;</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">sentence</span> <span class="n">log</span><span class="o">-</span><span class="n">probability</span> <span class="n">per</span> <span class="n">alternative</span><span class="o">&gt;</span>
<span class="p">}</span>
</pre></div>
</div>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="yokome.models.language_model.LanguageModel.production_dir">
<code class="sig-name descname">production_dir</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#yokome.models.language_model.LanguageModel.production_dir" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the directory where the model for production is stored.</p>
</dd></dl>

<dl class="method">
<dt id="yokome.models.language_model.LanguageModel.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">trn_set</em>, <em class="sig-param">evl_set</em>, <em class="sig-param">max_epochs=1</em>, <em class="sig-param">batch_size=1</em>, <em class="sig-param">max_generalization_loss=None</em>, <em class="sig-param">shuffle=False</em>, <em class="sig-param">random_state=None</em>, <em class="sig-param">verbose=False</em><span class="sig-paren">)</span><a class="headerlink" href="#yokome.models.language_model.LanguageModel.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Train the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trn_set</strong> – A sequence of sentences, a training set.  Each
sentence will be tokenized using the language object provided at
language model creation.</p></li>
<li><p><strong>trn_set</strong> – A sequence of sentences, an evaluation set.  Each
sentence will be tokenized using the language object provided at
language model creation.</p></li>
<li><p><strong>max_epochs</strong> (<em>int</em>) – The maximum number of epochs to train for.  The
actual number of epochs may be less if the training process stops
early.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – The number of sentences to estimate the
probability for in parallel.</p></li>
<li><p><strong>max_generalization_loss</strong> (<em>float</em>) – The maximum generalization loss at
which the training process is still continued.</p></li>
<li><p><strong>shuffle</strong> (<em>bool</em>) – Whether to shuffle the samples for each epoch.</p></li>
<li><p><strong>random_state</strong> – The random state used for shuffling.  May be a
<code class="xref py py-class docutils literal notranslate"><span class="pre">numpy.RandomState</span></code> instance, an <code class="docutils literal notranslate"><span class="pre">int</span></code> seed, or <code class="docutils literal notranslate"><span class="pre">None</span></code>.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, an unseeded pseudo-random number generator will be
used.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – Whether to show progress indicators.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="yokome.models.language_model.LanguageModel.training_dir">
<code class="sig-name descname">training_dir</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#yokome.models.language_model.LanguageModel.training_dir" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the directory where the model for training is stored.</p>
</dd></dl>

<dl class="method">
<dt id="yokome.models.language_model.LanguageModel.validate">
<code class="sig-name descname">validate</code><span class="sig-paren">(</span><em class="sig-param">vld_set</em>, <em class="sig-param">batch_size=1</em><span class="sig-paren">)</span><a class="headerlink" href="#yokome.models.language_model.LanguageModel.validate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the model performance on a validation set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vld_set</strong> – A sequence of sentences, a validation set.  Each
sentence will be tokenized using the language object provided at
language model creation.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – The number of sentences to estimate the
probability for in parallel.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary containing the metrics evaluated on the validation
set.  Contains an entry <code class="docutils literal notranslate"><span class="pre">'loss'</span></code> for the loss and an entry
<code class="docutils literal notranslate"><span class="pre">'global_step'</span></code> for the global step for which this validation was
performed.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="yokome.models.language_model.SaverHook">
<em class="property">class </em><code class="sig-prename descclassname">yokome.models.language_model.</code><code class="sig-name descname">SaverHook</code><span class="sig-paren">(</span><em class="sig-param">model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#yokome.models.language_model.SaverHook" title="Permalink to this definition">¶</a></dt>
<dd><p>A helper class that allows to save the model to one directory during training
and to provide the best model from a different directory for production
mode.</p>
<dl class="method">
<dt id="yokome.models.language_model.SaverHook.end">
<code class="sig-name descname">end</code><span class="sig-paren">(</span><em class="sig-param">session</em><span class="sig-paren">)</span><a class="headerlink" href="#yokome.models.language_model.SaverHook.end" title="Permalink to this definition">¶</a></dt>
<dd><p>Called at the end of session.</p>
<p>The <cite>session</cite> argument can be used in case the hook wants to run final ops,
such as saving a last checkpoint.</p>
<p>If <cite>session.run()</cite> raises exception other than OutOfRangeError or
StopIteration then <cite>end()</cite> is not called.
Note the difference between <cite>end()</cite> and <cite>after_run()</cite> behavior when
<cite>session.run()</cite> raises OutOfRangeError or StopIteration. In that case
<cite>end()</cite> is called but <cite>after_run()</cite> is not called.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>session: A TensorFlow Session that will be soon closed.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2019, Julian Betz.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.2.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>